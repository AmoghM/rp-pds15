{
 "metadata": {
  "name": "",
  "signature": "sha256:0f3fee66b6221a1295407b369e34cd94262bb567ea3c2bfdbb506c1d533ca891"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<DIV ALIGN=CENTER>\n",
      "\n",
      "# Introduction to Hadoop\n",
      "## Professor Robert J. Brunner\n",
      "  \n",
      "</DIV>  \n",
      "-----\n",
      "-----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Introduction\n",
      "\n",
      "In this Notebook, we will demonstrate how to run hadoop in a docker container.\n",
      "\n",
      "1. docker pull sequenceiq/hadoop-ubuntu:2.6.0\n",
      "2. docker run -it sequenceiq/hadoop-ubuntu:2.6.0 /etc/bootstrap.sh -bash\n",
      "3. /# mkdir htest\n",
      "4. /# cd htest/\n",
      "5. /htest# vi mapper.py\n",
      "6. /htest# vi reducer.py\n",
      "7. Get data\n",
      "8. /htest# wget http://central.maven.org/maven2/org/apache/hadoop/hadoop-streaming/2.6.0/hadoop-streaming-2.6.0.jar\n",
      "9. /htest# $HADOOP_PREFIX/bin/hadoop fs -mkdir -p wordcount/input \n",
      "10. /htest# $HADOOP_PREFIX/bin/hadoop fs -put data.txt  wordcount/input/text\n",
      "11. /htest# $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming-2.6.0.jar -files mapper.py,reducer.py -input wordcount/input -output wordcount/output  -mapper mapper.py -reducer reducer.py  \n",
      "\n",
      "Success!\n",
      "\n",
      "Other worthy commands:\n",
      "\n",
      "1. /htest# $HADOOP_PREFIX/bin/hadoop fs -rmdir wordcount/output\n",
      "2. /htest# $HADOOP_PREFIX/bin/hadoop fs -ls wordcount        \n",
      "\n",
      "\n",
      "-----\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Breakout Session: Hadoop\n",
      "\n",
      "During this session, you should first download the docker container, and follow the directions to get the basic word count example working.\n",
      "\n",
      "### Intermediate Challenge:\n",
      "\n",
      "Download the 2001.csv data and count how many flights in bins of 500 miles.\n",
      "\n",
      "### Advanced Challenge:\n",
      "\n",
      "count the flights in bins of 500 miles organized by airport.\n",
      "\n",
      "\n",
      "-----"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Additional References\n",
      "\n",
      "1. [Hadoop][1] Documentation\n",
      "\n",
      "-----\n",
      "\n",
      "[1]: http://\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Return to the [Week 8 Index](index.ipynb).\n",
      "\n",
      "-----"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}